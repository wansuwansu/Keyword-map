import streamlit as st
import time
import hmac
import hashlib
import base64
import requests
import pandas as pd
from datetime import datetime
import re

# ==========================================
# 0. API í‚¤ ë° ì„¤ì •
# ==========================================

# [1] ì¹´ì¹´ì˜¤ API
KAKAO_REST_KEY = "968344aed4aff4d7aeb37eb199767d5a"

# [2] ë„¤ì´ë²„ ê´‘ê³  API
AD_API_KEY = "01000000002855c92d066a6e30d3eaeafbe6adebd688d73c3dd901f151b52c430ddcad5c88"
AD_SECRET_KEY = "AQAAAAAoVcktBmpuMNPq6vvmrevWXrbXSbEoh/+/3U3vTcTLyA=="
AD_CUSTOMER_ID = "4173931"

# [3] ë„¤ì´ë²„ ê²€ìƒ‰ API
NAVER_SEARCH_ID = "dlOt9fIfGfpSj69uICWc"
NAVER_SEARCH_SECRET = "_rtIqpqYpd"

# [4] ìœ íŠœë¸Œ ë°ì´í„° API
YOUTUBE_API_KEY = "AIzaSyBPgiYOvrPJ4cacWQ42UQb_KZobCcpOIH0"

# --- í•„í„°ë§ ë° ì¹´í…Œê³ ë¦¬ ì„¤ì • ---
EXCLUDED_KEYWORDS = ["ìŠˆë§í¬", "ì¨ë§ˆì§€", "ìš¸ì„ë¼", "ì¸ëª¨ë“œ", "í‹°íƒ€ëŠ„"]
BAD_BLOGGER_NAMES = ["ë³‘ì›", "ì˜ì›", "í´ë¦¬ë‹‰", "í”¼ë¶€ê³¼", "ì„±í˜•ì™¸ê³¼", "í•œì˜ì›", "ì¹˜ê³¼", "ê³µì‹", "ì§„ë£Œ", "ë‹¥í„°", "ë©”ë””ì»¬", "ì„¼í„°", "ë·°í‹°ìƒµ"]
HOSPITAL_YT_KEYWORDS = ["ë³‘ì›", "ì˜ì›", "í´ë¦¬ë‹‰", "ì„±í˜•", "í”¼ë¶€ê³¼", "ë‹¥í„°", "Dr", "ì˜ì‚¬", "TV", "ë©”ë””ì»¬", "ê³µì‹", "Plastic", "Dermatology"]
CAT_DISEASE = ["ì—¬ë“œë¦„", "ì•„í† í”¼", "ìŠµì§„", "ë¬´ì¢€", "ì‚¬ë§ˆê·€", "í‹°ëˆˆ", "ë‘ë“œëŸ¬ê¸°", "íƒˆëª¨", "ê¸°ë¯¸", "ì¡í‹°", "ì ë¹¼ê¸°", "í”¼ì§€", "ëª¨ê³µ", "í‰í„°", "ìƒ‰ì†Œ", "ë‹¤ì´ì–´íŠ¸", "ë¹„ë§Œ", "í™ì¡°"]
CAT_PROCEDURE = ["ë³´í†¡ìŠ¤", "í•„ëŸ¬", "ë¦¬í”„íŒ…", "ì œëª¨", "ë ˆì´ì €", "ìŠ¤í‚¨ë¶€ìŠ¤í„°", "ì£¼ì‚¬", "í† ë‹", "ê´€ë¦¬", "ë¯¸ë°±", "ì§€ë°©ë¶„í•´", "ë¸Œì´ì˜¬ë ›", "ë¦¬ì¥¬ë€", "ì¨ë§ˆì§€"]

# ==========================================
# 1. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ëª¨ìŒ
# ==========================================

# (1) ì¹´ì¹´ì˜¤ ì¥ì†Œ ê²€ìƒ‰
def search_places_kakao(query):
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_REST_KEY}"}
    try:
        res = requests.get(url, params={"query": query, "size": 15}, headers=headers)
        if res.status_code == 200: return res.json()['documents']
        return []
    except: return []

# (2) ì¹´ì¹´ì˜¤ ê·¼ì²˜ ì§€í•˜ì² ì—­ ì°¾ê¸°
def get_nearest_station(x, y):
    url = "https://dapi.kakao.com/v2/local/search/category.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_REST_KEY}"}
    params = {"category_group_code": "SW8", "x": x, "y": y, "radius": 1500, "sort": "distance"}
    try:
        res = requests.get(url, params=params, headers=headers)
        if res.status_code == 200 and res.json()['documents']:
            return res.json()['documents'][0]['place_name']
        return None
    except: return None

# (3) ì£¼ì†Œ íŒŒì‹± í—¬í¼
def parse_address(place):
    addr = place['address_name']
    parts = addr.split()
    si = next((p for p in parts if p.endswith('ì‹œ') or p.endswith('ë„')), "")
    gu = next((p for p in parts if p.endswith('êµ¬') or p.endswith('êµ°')), "")
    dong = next((p for p in parts if p.endswith('ë™') or p.endswith('ë¦¬') or p.endswith('ê°€')), "")
    return {"name": place['place_name'], "full_addr": addr, "si": si, "gu": gu, "dong": dong, "x": place['x'], "y": place['y']}

# (4) ë„¤ì´ë²„ ê´‘ê³  API
def get_naver_expanded_rankings(seed_keywords, filter_regions):
    uri = '/keywordstool'
    timestamp = str(int(time.time() * 1000))
    msg = f"{timestamp}.GET.{uri}"
    signature = base64.b64encode(hmac.new(bytes(AD_SECRET_KEY, 'UTF-8'), bytes(msg, 'UTF-8'), hashlib.sha256).digest())
    headers = {'X-Timestamp': timestamp, 'X-API-KEY': AD_API_KEY, 'X-Customer': AD_CUSTOMER_ID, 'X-Signature': signature}
    
    clean_seeds = list(set([k.replace(" ", "") for k in seed_keywords]))[:5]
    try:
        res = requests.get("https://api.naver.com" + uri, params={'hintKeywords': ','.join(clean_seeds), 'showDetail': '1'}, headers=headers)
        if res.status_code == 200:
            data = res.json()
            results = []
            for item in data.get('keywordList', []):
                kwd = item['relKeyword'].replace(" ", "")
                if not any(region in kwd for region in filter_regions): continue
                if any(bad in kwd for bad in EXCLUDED_KEYWORDS): continue
                p = 5 if isinstance(item['monthlyPcQcCnt'], str) else item['monthlyPcQcCnt']
                m = 5 if isinstance(item['monthlyMobileQcCnt'], str) else item['monthlyMobileQcCnt']
                
                category = "ê¸°íƒ€"
                if "í”¼ë¶€ê³¼" in kwd or "ì˜ì›" in kwd or "ë³‘ì›" in kwd or "í´ë¦¬ë‹‰" in kwd: category = "ğŸ¥ ë©”ì¸(ë³‘ì›)"
                elif any(d in kwd for d in CAT_DISEASE): category = "ğŸ’Š ì§ˆí™˜/ì¹˜ë£Œ"
                elif any(p in kwd for p in CAT_PROCEDURE): category = "ğŸ’‰ ì‹œìˆ /ë·°í‹°"
                
                results.append({'category': category, 'key': item['relKeyword'], 'total': p + m, 'mobile': m})
            return results
        return []
    except: return []

# (5) ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰
def search_bloggers(keyword, display=30):
    url = "https://openapi.naver.com/v1/search/blog.json"
    headers = {"X-Naver-Client-Id": NAVER_SEARCH_ID, "X-Naver-Client-Secret": NAVER_SEARCH_SECRET}
    params = {"query": keyword, "display": display, "sort": "sim"}
    try:
        res = requests.get(url, params=params, headers=headers)
        if res.status_code == 200: return res.json()['items']
        return None
    except: return None

# (6) ìœ íŠœë¸Œ ê³ ê¸‰ ê²€ìƒ‰ (ìˆ˜ì •ë¨: 1ë¶„ ì œí•œ ì‚­ì œ, ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€)
def search_youtube_advanced(keyword, period_opt, sort_opt, format_opt):
    published_after = None
    now = datetime.now()
    if period_opt == "ìµœê·¼ 1ì£¼": published_after = (now - pd.Timedelta(weeks=1)).strftime('%Y-%m-%dT%H:%M:%SZ')
    elif period_opt == "ìµœê·¼ 1ê°œì›”": published_after = (now - pd.Timedelta(days=30)).strftime('%Y-%m-%dT%H:%M:%SZ')
    elif period_opt == "ìµœê·¼ 3ê°œì›”": published_after = (now - pd.Timedelta(days=90)).strftime('%Y-%m-%dT%H:%M:%SZ')
    
    api_order = "viewCount" 
    if sort_opt == "ë‚ ì§œìˆœ": api_order = "date"
    elif sort_opt == "ì¡°íšŒìˆœ": api_order = "viewCount"
    elif sort_opt == "ëŒ“ê¸€ìˆœ": api_order = "relevance"

    # [ìˆ˜ì •] 1ë¶„ ë¯¸ë§Œ ì œí•œ ê¸°ëŠ¥ ì‚­ì œ (videoDuration íŒŒë¼ë¯¸í„° ë¯¸ì‚¬ìš©)
    # ëŒ€ì‹  ì¿¼ë¦¬ì— 'shorts' ë“±ì„ ì¶”ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ ê·¸ëƒ¥ ì „ì²´ ê²€ìƒ‰
    final_query = keyword
    if format_opt == "ì„¸ë¡œí˜• (ì‡¼ì¸ /ë¦´ìŠ¤)":
        final_query = f"{keyword} shorts" # ì‡¼ì¸  í‚¤ì›Œë“œ ì¶”ê°€ë¡œ ìœ ë„

    search_url = "https://www.googleapis.com/youtube/v3/search"
    params = {
        "part": "snippet",
        "q": final_query,
        "key": YOUTUBE_API_KEY,
        "maxResults": 50, # [ìˆ˜ì •] ê²€ìƒ‰ ë²”ìœ„ë¥¼ 50ê°œë¡œ ëŠ˜ë ¤ì„œ ì œëª©ì— ì—†ì–´ë„ ê±¸ë¦¬ê²Œ í•¨
        "type": "video",
        "order": api_order
    }
    if published_after: params['publishedAfter'] = published_after

    try:
        res = requests.get(search_url, params=params)
        if res.status_code != 200: return None
        video_items = res.json().get('items', [])
        if not video_items: return []

        video_ids = [item['id']['videoId'] for item in video_items]
        channel_ids = [item['snippet']['channelId'] for item in video_items]

        stats_url = "https://www.googleapis.com/youtube/v3/videos"
        stats_res = requests.get(stats_url, params={"part": "statistics,contentDetails", "id": ",".join(video_ids), "key": YOUTUBE_API_KEY})
        video_stats = {item['id']: item for item in stats_res.json().get('items', [])}

        chan_url = "https://www.googleapis.com/youtube/v3/channels"
        chan_res = requests.get(chan_url, params={"part": "statistics,snippet", "id": ",".join(channel_ids), "key": YOUTUBE_API_KEY})
        channel_infos = {item['id']: item for item in chan_res.json().get('items', [])}

        results = []
        for item in video_items:
            vid = item['id']['videoId']
            cid = item['snippet']['channelId']
            
            v_stat = video_stats.get(vid, {}).get('statistics', {})
            c_stat = channel_infos.get(cid, {}).get('statistics', {})
            c_snip = channel_infos.get(cid, {}).get('snippet', {})
            
            view_count = int(v_stat.get('viewCount', 0))
            comment_count = int(v_stat.get('commentCount', 0))
            sub_count = int(c_stat.get('subscriberCount', 0))
            channel_name = item['snippet']['channelTitle']
            
            account_type = "ğŸ‘¤ ì¼ë°˜/ì¸í”Œë£¨ì–¸ì„œ"
            if any(k in channel_name for k in HOSPITAL_YT_KEYWORDS) or any(k in c_snip.get('description', '') for k in HOSPITAL_YT_KEYWORDS):
                account_type = "ğŸ¥ ë³‘ì›/ê³µì‹"

            is_rising = False
            if 100 < sub_count < 50000:
                if view_count > (sub_count * 0.5): is_rising = True

            results.append({
                "title": item['snippet']['title'],
                "thumbnail": item['snippet']['thumbnails']['medium']['url'],
                "channel": channel_name,
                "published": item['snippet']['publishedAt'][:10],
                "views": view_count,
                "comments": comment_count,
                "subs": sub_count,
                "url": f"https://www.youtube.com/watch?v={vid}",
                "is_rising": is_rising,
                "type": account_type
            })
        
        if sort_opt == "ëŒ“ê¸€ìˆœ": return sorted(results, key=lambda x: x['comments'], reverse=True)
        elif sort_opt == "ì¡°íšŒìˆœ": return sorted(results, key=lambda x: x['views'], reverse=True)
        else: return results 

    except: return None

# (7) ì¸ìŠ¤íƒ€ê·¸ë¨ ê²€ìƒ‰ (ë„¤ì´ë²„ ì›¹ ê²€ìƒ‰ í™œìš© - ìš°íšŒë²•)
def search_instagram_via_naver(keyword):
    # ë„¤ì´ë²„ ì›¹ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ 'site:instagram.com' ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
    url = "https://openapi.naver.com/v1/search/webkr.json"
    headers = {"X-Naver-Client-Id": NAVER_SEARCH_ID, "X-Naver-Client-Secret": NAVER_SEARCH_SECRET}
    
    # ì¿¼ë¦¬ ì˜ˆì‹œ: "ë¦¬ì¥¬ë€ site:instagram.com"
    query = f"{keyword} site:instagram.com"
    params = {"query": query, "display": 30}
    
    try:
        res = requests.get(url, params=params, headers=headers)
        if res.status_code == 200:
            items = res.json()['items']
            results = []
            for item in items:
                link = item['link']
                # ì¸ìŠ¤íƒ€ ë§í¬ë§Œ í•„í„°ë§
                if "instagram.com" in link:
                    # ì œëª©ì—ì„œ íƒœê·¸ ì œê±°
                    title = item['title'].replace("<b>", "").replace("</b>", "")
                    description = item['description'].replace("<b>", "").replace("</b>", "")
                    
                    # ê³„ì •ëª… ì¶”ì¶œ ì‹œë„ (URL êµ¬ì¡°: instagram.com/username/...)
                    username = "Instagram User"
                    try:
                        parts = link.split("instagram.com/")
                        if len(parts) > 1:
                            username = parts[1].split("/")[0].split("?")[0]
                    except: pass
                    
                    results.append({
                        "username": username,
                        "title": title,
                        "desc": description,
                        "link": link
                    })
            return results
        return None
    except: return None

# ==========================================
# 2. í™”ë©´ UI êµ¬ì„±
# ==========================================
st.set_page_config(page_title="ë³‘ì› ë§ˆì¼€íŒ… ë§ˆìŠ¤í„°", layout="wide")
st.title("ğŸ¥ ë³‘ì› ë§ˆì¼€íŒ… ì˜¬ì¸ì› íˆ´")

if 'search_results' not in st.session_state: st.session_state.search_results = []

# íƒ­ ë©”ë‰´ (4ê°œë¡œ í™•ì¥)
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š í‚¤ì›Œë“œ ë¶„ì„", "ğŸ“ ë¸”ë¡œê±° ë°œêµ´", "ğŸ“º ìœ íŠœë²„ ë°œêµ´", "ğŸ“¸ ì¸ìŠ¤íƒ€ ë°œêµ´"])

# [íƒ­ 1] í‚¤ì›Œë“œ ë¶„ì„
with tab1:
    st.header("1. ë³‘ì› ê²€ìƒ‰ ë° ìë™ ìƒê¶Œ ë¶„ì„")
    with st.form("search_form"):
        col1, col2 = st.columns([3, 1])
        with col1: h_query = st.text_input("ë³‘ì›ëª… ì…ë ¥", placeholder="ì˜ˆ: ë””ìƒ¤ì¸í”¼ë¶€ê³¼ ëŒ€ë¦¼")
        with col2: search_btn = st.form_submit_button("ğŸ” ë³‘ì› ì°¾ê¸°")
            
    if search_btn and h_query:
        places = search_places_kakao(h_query)
        if places: st.session_state.search_results = places
        else: st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if st.session_state.search_results:
        st.divider()
        st.subheader("ğŸ“ ë¶„ì„í•  ì§€ì ì„ ì„ íƒí•´ì£¼ì„¸ìš”")
        options = {f"{p['place_name']} ({p['address_name']})": idx for idx, p in enumerate(st.session_state.search_results)}
        choice = st.radio("ê²€ìƒ‰ ê²°ê³¼:", list(options.keys()))
        
        if choice:
            idx = options[choice]
            target = st.session_state.search_results[idx]
            st.divider()
            col_a, col_b = st.columns([1, 4])
            with col_a: category_seed = st.text_input("ëŒ€í‘œ í‚¤ì›Œë“œ", value="í”¼ë¶€ê³¼")
            with col_b: 
                st.write("")
                st.write("")
                analyze_btn = st.button("ğŸš€ ìë™ ìƒê¶Œ ë¶„ì„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ")
            
            if analyze_btn:
                with st.spinner(f"'{target['place_name']}' ìƒê¶Œ ì •ë°€ ë¶„ì„ ì¤‘..."):
                    loc = parse_address(target)
                    si, gu, dong = loc['si'], loc['gu'], loc['dong']
                    short_si = si.replace("ê´‘ì—­ì‹œ", "").replace("íŠ¹ë³„ì‹œ", "").replace("íŠ¹ë³„ìì¹˜ì‹œ", "").strip()
                    short_gu = gu.replace("êµ¬", "") 
                    short_dong = dong.replace("ë™", "")

                    station_name = get_nearest_station(loc['x'], loc['y'])
                    hot_place = ""
                    if station_name: hot_place = station_name.replace("ì—­", "").split()[0]

                    seed_keywords = []
                    filter_regions = []
                    if hot_place:
                        seed_keywords.append(f"{hot_place}{category_seed}")
                        filter_regions.append(hot_place)
                    if short_gu:
                        seed_keywords.append(f"{short_gu}{category_seed}")
                        filter_regions.append(short_gu)
                    seed_keywords.append(f"{short_dong}{category_seed}")
                    filter_regions.append(dong)
                    filter_regions.append(short_dong)
                    if short_si: filter_regions.append(short_si)

                    st.info(f"ğŸ“ ë¶„ì„ ë²”ìœ„: {hot_place if hot_place else '(ì—­ì„¸ê¶Œ ì—†ìŒ)'}, {short_gu}, {dong}")
                    
                    rankings = get_naver_expanded_rankings(seed_keywords, filter_regions)
                    
                    if rankings:
                        df = pd.DataFrame(rankings)
                        cats = ["ğŸ¥ ë©”ì¸(ë³‘ì›)", "ğŸ’‰ ì‹œìˆ /ë·°í‹°", "ğŸ’Š ì§ˆí™˜/ì¹˜ë£Œ"]
                        st.divider()
                        cols = st.columns(3)
                        for idx, cat in enumerate(cats):
                            with cols[idx]:
                                st.subheader(cat)
                                subset = df[df['category'] == cat].sort_values('total', ascending=False).head(10)
                                if not subset.empty:
                                    for _, row in subset.iterrows():
                                        st.markdown(f"<div style='background-color:white; padding:10px; border-radius:8px; border:1px solid #e0e0e0; margin-bottom:8px;'><div style='font-weight:bold;'>{row['key']}</div><div style='color:#555; font-size:0.8em;'>ì›” {row['total']:,}íšŒ</div></div>", unsafe_allow_html=True)
                                else: st.caption("ê²°ê³¼ ì—†ìŒ")
                        st.divider()
                        csv = df.sort_values(['category', 'total'], ascending=[True, False]).to_csv(index=False).encode('utf-8-sig')
                        st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{target['place_name']}_ë¶„ì„.csv", "text/csv")
                    else: st.error("ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")

# [íƒ­ 2] ë¸”ë¡œê±° ë°œêµ´
with tab2:
    st.header("2. ì§€ì—­ ì „ë¬¸ ë·°í‹° ë¸”ë¡œê±° ë°œêµ´")
    with st.form("blog_form"):
        col_b1, col_b2 = st.columns([3, 1])
        with col_b1: region_input = st.text_input("íƒ€ê²Ÿ ì§€ì—­ëª…", placeholder="ì˜ˆ: ì˜ë“±í¬, ì„œë©´")
        with col_b2: submit_blog = st.form_submit_button("ğŸ•µï¸â€â™€ï¸ ë¸”ë¡œê±° ì°¾ê¸°")
        
    if submit_blog:
        if region_input:
            search_keywords = [f"{region_input} í”¼ë¶€ê³¼ í›„ê¸°", f"{region_input} ë·°í‹°", f"{region_input} ì‹œìˆ  ë‚´ëˆë‚´ì‚°"]
            with st.spinner("ë¸”ë¡œê±° ë¶„ì„ ì¤‘..."):
                all_items = []
                for k in search_keywords:
                    res = search_bloggers(k, display=30)
                    if res: all_items.extend(res)
                
                if all_items:
                    data = []
                    seen_bloggers = set()
                    for item in all_items:
                        blogger_name = item['bloggername']
                        if blogger_name in seen_bloggers: continue
                        if any(bad in blogger_name for bad in BAD_BLOGGER_NAMES): continue
                        seen_bloggers.add(blogger_name)
                        title = item['title'].replace("<b>", "").replace("</b>", "")
                        post_date = item['postdate']
                        try:
                            days_ago = (datetime.now() - datetime.strptime(post_date, "%Y%m%d")).days
                            status = "ğŸŸ¢ í™œë°œ" if days_ago < 30 else "ğŸ”´ ëœ¸í•¨"
                        except: days_ago, status = "-", "âšª í™•ì¸í•„ìš”"
                        data.append({"ë¸”ë¡œê±°": blogger_name, "ê¸€ ì œëª©": item['link'], "ì œëª©_í‘œì‹œ": title, "ì‘ì„±ì¼": f"{post_date[:4]}-{post_date[4:6]}-{post_date[6:]}", "ìƒíƒœ": status})
                    
                    if data:
                        st.success(f"ğŸ” {len(data)}ëª…ì˜ ì¸í”Œë£¨ì–¸ì„œ ë°œê²¬!")
                        for row in data[:20]:
                            with st.expander(f"[{row['ìƒíƒœ']}] {row['ë¸”ë¡œê±°']}"):
                                st.write(f"**ê¸€:** [{row['ì œëª©_í‘œì‹œ']}]({row['ê¸€ ì œëª©']})")
                    else: st.warning("ì¡°ê±´ì— ë§ëŠ” ë¸”ë¡œê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# [íƒ­ 3] ìœ íŠœë²„ ë°œêµ´ (ìˆ˜ì •ë¨)
with tab3:
    st.header("3. ìœ íŠœë¸Œ ì¸í”Œë£¨ì–¸ì„œ ì •ë°€ ë°œêµ´")
    with st.form("youtube_form"):
        yt_keyword = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ë¦¬ì¥¬ë€ íëŸ¬ í›„ê¸°")
        c1, c2, c3 = st.columns(3)
        with c1: period_opt = st.selectbox("ğŸ“… ê¸°ê°„", ["ì „ì²´", "ìµœê·¼ 1ì£¼", "ìµœê·¼ 1ê°œì›”", "ìµœê·¼ 3ê°œì›”"])
        with c2: sort_opt = st.selectbox("ğŸ“‰ ì •ë ¬", ["ì¡°íšŒìˆœ", "ë‚ ì§œìˆœ", "ëŒ“ê¸€ìˆœ(ì†Œí†µì™•)"])
        with c3: format_opt = st.selectbox("ğŸ“± í˜•ì‹", ["ìƒê´€ì—†ìŒ", "ê°€ë¡œí˜• (ì¼ë°˜)", "ì„¸ë¡œí˜• (ì‡¼ì¸ /ë¦´ìŠ¤)"])
        st.write("")
        submit_yt = st.form_submit_button("ğŸ“º ì˜ìƒ ì°¾ê¸°")

    if submit_yt:
        if yt_keyword:
            with st.spinner("ë°ì´í„° ë¶„ì„ ë° ì±„ë„ ì„±í–¥ íŒŒì•… ì¤‘..."):
                results = search_youtube_advanced(yt_keyword, period_opt, sort_opt, format_opt)
                if results:
                    st.success(f"ì¡°ê±´ì— ë§ëŠ” ì˜ìƒ {len(results)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    for row in results:
                        with st.container():
                            col_img, col_txt = st.columns([1, 2.5])
                            with col_img: st.image(row['thumbnail'], use_container_width=True)
                            with col_txt:
                                st.markdown(f"#### [{row['title']}]({row['url']})")
                                badges = []
                                if "ë³‘ì›" in row['type']: badges.append(f"<span style='background-color:#ffebeb; color:#ff4b4b; padding:2px 6px; border-radius:4px; font-size:0.8em;'>{row['type']}</span>")
                                else: badges.append(f"<span style='background-color:#e8fdf5; color:#21c35e; padding:2px 6px; border-radius:4px; font-size:0.8em;'>{row['type']}</span>")
                                if row['is_rising']: badges.append("<span style='background-color:#fff8c4; color:#d97706; padding:2px 6px; border-radius:4px; font-size:0.8em;'>ğŸ”¥ ë¼ì´ì§•</span>")
                                st.markdown(" ".join(badges), unsafe_allow_html=True)
                                st.markdown(f"ì±„ë„: {row['channel']} (êµ¬ë… {row['subs']:,}) | ì¡°íšŒ: {row['views']:,} | ëŒ“ê¸€: {row['comments']:,}")
                            st.divider()
                else: st.warning("ì¡°ê±´ì— ë§ëŠ” ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")

# [íƒ­ 4] ì¸ìŠ¤íƒ€ê·¸ë¨ ë°œêµ´ (New!)
with tab4:
    st.header("4. ì¸ìŠ¤íƒ€ê·¸ë¨ ì¸í”Œë£¨ì–¸ì„œ ë°œêµ´")
    st.caption("ë„¤ì´ë²„ ê²€ìƒ‰ ì—”ì§„ì„ í™œìš©í•˜ì—¬ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤. (API ì œí•œ ìš°íšŒ)")
    
    with st.form("insta_form"):
        i_keyword = st.text_input("ì¸ìŠ¤íƒ€ ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ê°•ë‚¨ì—­ í”¼ë¶€ê³¼, ì˜¤ìš´ì™„")
        submit_insta = st.form_submit_button("ğŸ“¸ ì¸ìŠ¤íƒ€ ê²Œì‹œë¬¼ ì°¾ê¸°")
        
    if submit_insta:
        if i_keyword:
            with st.spinner("ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ ìŠ¤ìº” ì¤‘..."):
                results = search_instagram_via_naver(i_keyword)
                if results:
                    st.success(f"ê´€ë ¨ëœ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ {len(results)}ê°œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
                    
                    # 3ì—´ ì¹´ë“œ ë°°ì¹˜
                    cols = st.columns(3)
                    for idx, row in enumerate(results):
                        with cols[idx % 3]:
                            st.markdown(f"""
                            <div style="border:1px solid #e0e0e0; border-radius:10px; padding:15px; margin-bottom:15px; height:250px; overflow:hidden;">
                                <div style="font-weight:bold; font-size:1.1em; margin-bottom:5px; color:#E1306C;">@{row['username']}</div>
                                <div style="font-size:0.9em; font-weight:bold; margin-bottom:10px;"><a href="{row['link']}" target="_blank" style="text-decoration:none; color:black;">{row['title']}</a></div>
                                <div style="font-size:0.8em; color:#666;">{row['desc'][:80]}...</div>
                                <div style="margin-top:10px;"><a href="{row['link']}" target="_blank" style="background-color:#E1306C; color:white; padding:5px 10px; text-decoration:none; border-radius:5px; font-size:0.8em;">ê²Œì‹œë¬¼ ë³´ê¸°</a></div>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")